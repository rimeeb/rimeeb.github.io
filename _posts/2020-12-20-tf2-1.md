---
title: Tensorflow Layers
date: 2020-12-20 22:25:00 +0900
categories: [딥러닝]
tags: [딥러닝, AI, tensorflow, 텐서플로, 텐서플로2.0]     # TAG names should always be lowercase
---

### Tensorflow Layers

텐서플로2.0 이후 부터 대부분의 모듈이 tf.keras.layers로 대체되었다.  

레이어들은 객체를 만든 후 입력값을 설정하거나 생성과 동시에 사용할 수 있다.
₩₩₩
# 1. 객체 생성 후 입력값 설정
dense = tf.keras.layers.Dense(...)
output = dense(input)

# 2. 객체 생성과 동시에 입력값 설정
output = tf.keras.layers.Dense(...)(input)
₩₩₩


#### tf.keras.layers.Dense
가장 기본적인 형태  
$$y = {f(Wx+b)}$$
>x: 입력 벡터  
>W: 가중치 Weight matrix 
>b: constant vector (편향 벡터)
>f: activation function (활성화 함수)

개인적으로 잘 이해가 안가던 parameter setting 들만 정리했다
* kernel_regularizer
* bias_regularizer
* activity_regularizer
* kernel_constraint
Optimizer에 의해 업데이트 된 후에 가중치에 적용되는 부가적인 제약 함수
norm_constraint, value_constraint
* bias_constraint
Optimizer에 의해 업데이트 된 후에 편향에 적용되는 부가적인 제약 함수

\\\
INPUT_SIZE = (20, 10)

inputs = tf.keras.layers.Input(shape=INPUT_SIZE)
hidden = tf.keras.layers.Dense(units=5, activation=tf.nn.sigmoid)(inputs)
output = tf.keras.layers.Dense(units=2, activation=tf.nn.sigmoid)(hidden)
\\\

#### tf.keras.layers.Dropout
Overfitting을 피하기 위한 대표적인 regularization 방법인 Dropout
굉장히 쉽게 구현을 할 수 있으며 boosting 효과가 있다. 

#### tf.keras.layers.Conv1D

Conv1D 1-D Array(vector)
Conv2D 2-D Array(matrix)
Conv3D 3-D Array(tensor)

입력값의 차원 수 와 높이가 동일하게 설정되기 때문에 높이는 필요하지 않음. 가로 길이만 필요.
채널을 몇개 쓸지만 결정하면 됨. (필터)

ex)
input  size: 5x10
kernel size: 2 (1x2x10)
filter size: 10
output size: 1x4x10

* padding: "VALID" or "SAME"
* strides: 1이 아닌경우, dilation_rates 는 1만 설정 할 수 있다
* dilation_rate: dilation 합성곱에 사용 할 값. 1이 아닌 경우, strides 1만 설정 할 수 있다

#### tf.keras.layers.MaxPool1D

합성곱과 함께 쓰이는 기법. 보통 feature map의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용되는 기법. 
주로 두 가지 pooling이 있다. Max-Pooling과 Average-Pooling 

```
INPUT_SIZE = (1, 28, 28)

inputs = tf.keras.Input(shape = INPUT_SIZE)
dropout = tf.keras.layers.Dropout(rate=0.2)(input)
conv = tf.keras.layers.Conv1D(
	filters=10,
	kernel_size=3,
	padding='same',
	activation=tf.nn.relu)(input)
max_pool = tf.keras.layers.MaxPool1D(pool_size=3, padding='same')(conv)
flatten = tf.keras.Flatten()(max_pool)
hidden = tf.keras.layers.Dense(units = 50, activation = tf.nn.relu)(flatten)
output = tf.keras.layers.Dense(units = 10, activation = tf.nn.softmax)(hidden)
```

### TensorFlow 2.0

* 파이썬에 적합하도록 Eager execution 통합
> 이전에는 그래프를 만든 후 세션을 통해 그래프를 실행하는 방식이었다.
> 하지만 tf2.0부터는 연산을 구성하면서 동시에 값을 바로 확인할 수 있다.
* No more globals
* Functions, not sessions
* Keras 활용 권장
> Sequential API
> Functional API
> Functional/Sequential API + Custom Layers
> Subclassing (Custom Model)

#### Sequential API
순차적인 모델 구축
하나의 플로우만 계산 가능
간단한 레이어의 스택 구조에 적합

활용하기 어려운 모델 구조
* 다중 입력값 모델(Multi-input models)
* 다중 출력값 모델(Multi-output models)
* 공유 층을 활용하는 모델(Models with shared layers)
* 데이터 흐름이 순차적이지 않은 모델(Models with non-sequential data flows)
> Functional 혹은 Subclassing이 적절할 것

#### Functional API
input 모듈을 선언해야 함. 입력 shape을 정의.









